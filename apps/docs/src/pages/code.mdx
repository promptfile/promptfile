import { Models } from '@/components/Models'
import Image from 'next/image'
import codeSnippet from '@/images/screenshots/codesnippet.png'

import indexCompletion from '@/images/screenshots/index-completion.png'
import executableCode from '@/images/screenshots/CodeOutsideBlock.png'
import interpolate from '@/images/screenshots/interpolate.png'

export const description = 'Work with code inside Glass .'

# Why mix code and text?

Not only are LLMs particularly good at working with code, including code inside your prompts allows you to make prompts more dynamic and powerful. You can use code to load data into a prompt or to take specific actions.

However, you might also want to include code as part of your request. For example, you might want to include a code snippet to provide what code you are trying to debug alongside the LLM. Or you might want to include a code snippet to show examples of what code you are trying to generate.

## Executable Code

Anything not wrapped in a [block](/blocks) is considered executable code. You can use this to define variables, functions, or anything else you need to make your prompt work. The language defaults to TypeScript, but you can change it in the front matter or in [VScode settings](/vscode). This allows you to move easily from code to text and back again. Use code to load data into a prompt or to take specific actions.

You can access your variables inside your prompt using string interpolation. `${someVariable}`.

<Image src={executableCode} />

## Code Snippets

Code snippets are ways to include code in your request that is not executed. Specify the language you are using. All languages supported by Markdown's code snippets are supported in Glass.

<Image src={codeSnippet} />
